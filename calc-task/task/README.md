Расчетное задание

**«Вычисление определенного интеграла с использованием технологий OpenMP и MPI»**

(для группы ВМ-22м)

1. **Введение**

**Приближенное вычисление определенного интеграла методом прямоугольников.**

На рисунке 1 приведена иллюстрация вычисления определенного интеграла методом прямоугольников на примере приближенного вычисления числа π. 

![](Aspose.Words.96d2366a-c0b3-408d-9fa0-3bf2afdc4b86.001.png)

Рисунок 1 – Иллюстрация приближенного вычисления определенного интеграла методом прямоугольников

`	`Интервал интегрирования [0, 1] делится на *n* отрезков (на рисунке 1 *n*=10). Длина каждого отрезка определяется в виде: *h*=(длина интервала интегрирования/*n*). В примере на рисунке 1 ![](Aspose.Words.96d2366a-c0b3-408d-9fa0-3bf2afdc4b86.002.png). Интеграл заменяется суммой площадей прямоугольников, ширина которых равна шагу интегрирования *h*, а высота – значениям подынтегральной функции в средних точках отрезков, на которые разбивается весь интервал интегрирования. Очевидно, что главный параметр алгоритма – число отрезков разбиения *n*. Чем больше *n*, тем выше точность аппроксимации определенного интеграла.

`	`Последовательная реализация приближенного вычисления определенного интеграла приводит к циклу, в теле которого вычисляются значения подынтегральной функции (см. рисунок 1) и происходит накапливающее суммирование.

Параллельная реализация цикла на основе OpenMP может наиболее простым способом быть реализована с использованием директивы **#pragma omp for *reduction (+: имя\_переменной\_суммы\_значений).*** 

Параллельная реализация на основе MPI предполагает распределение итераций цикла между процессами, например циклическое, частичное суммирование результатов для каждого процесса, а затем, после завершения цикла, сборки частичных сумм с помощью функции **MPI\_Reduce**.

1. **Рабочее задание**

1\. Написать, отладить, скомпилировать и запустить на гибридном вычислительном кластере СФМЭИ программу **последовательного** вычисления определенного интеграла. Предусмотреть замер времени выполнения программы с использованием функции **omp\_get\_wtime (). *Необходимо предусмотреть контроль правильности вычисления определенного интеграла.*** Индивидуальные задания в соответствии с номером по журналу взять из таблицы 1.

2\. Получить зависимость времени выполнения **последовательной** программы от числа отрезков разбиения интервала интегрирования *n.* Максимальное значение *n* выбрать таким, чтобы время выполнения последовательной версии достигало величины порядка 1- 5 секунд.

3\. Написать, отладить, скомпилировать и запустить на гибридном вычислительном кластере СФМЭИ (**на узле управления (УУ)**) программу **параллельного** вычисления определенного интеграла с помощью OpenMP. Предусмотреть замер времени выполнения **параллельной** программы**.** Число нитей для реализации параллельной программы выбрать по умолчанию (максимально возможным для узла управления). При этом необходимо определить это число с помощью функции **omp\_get\_num\_threads()** или переменной окружения **OMP\_NUM\_THREADS** и вывести на консоль (или в файл) в качестве одного из результатов работы программы.

4\.** Получить зависимость времени выполнения параллельной программы от числа отрезков разбиения интервала интегрирования *n.*

5\. Получить зависимость ускорения параллельного алгоритма S<sub>пар</sub>=(T<sub>посл</sub>/T<sub>пар</sub>), где T<sub>посл</sub> - время выполнения последовательного алгоритма, T<sub>пар</sub> – время выполнения параллельного алгоритма, от числа отрезков разбиения интервала интегрирования *n.*

6\. При максимальном *n (из пункта 2 рабочего задания)* получить зависимость времени выполнения параллельной программы от числа нитей, использующихся в параллельной секции. Число нитей изменять с помощью функции **omp\_set\_num\_threads()** или переменной окружения **OMP\_NUM\_THREADS.**

7\. Запустить параллельную программу на вычислительном узле 1 (ВУ1) и вычислительном узле 2 (ВУ2).

8\. Сравнить время вычисления параллельной программы при максимальном n (из пункта 2) и **максимальном** числе нитей на узлах УУ, ВУ1, ВУ2.

9\. Сравнить время вычисления параллельной программы при максимальном n и **одинаковом (32)** числе нитей на узлах УУ, ВУ1, ВУ2.

10\. Написать, отладить, скомпилировать и запустить на гибридном вычислительном кластере СФМЭИ (на УУ) MPI-программу вычисления определенного интеграла. Предусмотреть замер времени выполнения программы, контроль правильности вычисления интеграла. Индивидуальные задания в соответствии с номером по журналу взять из таблицы 1.

11\. Повторить пункты 4-9 для MPI-программы. Естественно, число процессов для MPI задается средой выполнения.

12\. Сравнить полученную в пункте 5 зависимость для OpenMP и MPI (число нитей (процессов) в OpenMP и MPI должно быть одинаковым, запуск производится на одном и том же узле).

13\. При максимальном n продлить полученную в пункте 6 для MPI-программы зависимость времени выполнения параллельной программы от числа процессов, используя запуск программы на двух вычислительных узлах (число процессов – до 80), на трех узлах (число процессов – до 112).

14\. Сравнить полученное в MPI максимальное ускорение с максимальным ускорением, полученным с помощью OpenMP.

15\. Все полученные зависимости оформить в виде графиков. При необходимости использовать табличную форму представления.

Таблица 1 – Индивидуальные задания по вычислению определенного интеграла


|№ по журналу|Интеграл|
| :- | :- |
|**19**|![](Aspose.Words.96d2366a-c0b3-408d-9fa0-3bf2afdc4b86.003.png)|

1. **Содержание расчетного задания**
1. Листинги программ.
1. Команды компиляции, запуска программ.
1. Графики зависимостей.
1. Анализ результатов.

**Расчетное задание в электронном виде предоставить преподавателю или направить по электронной почте по адресу**: <director@sbmpei.ru>.
